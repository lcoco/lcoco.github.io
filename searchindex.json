{"categories":[{"title":"Java","uri":"https://lcoco.github.io/categories/java/"},{"title":"Python","uri":"https://lcoco.github.io/categories/python/"}],"posts":[{"content":" 35 个 Java 代码优化小技巧 前言 代码优化，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运行效率有什么影响呢？这个问题我是这么考虑的，就像大海里面的鲸鱼一样，它吃一条小虾米有用吗？没用，但是，吃的小虾米一多之后，鲸鱼就被喂饱了。代码优化也是一样，如果项目着眼于尽快无 BUG 上线，那么此时可以抓大放小，代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码，这时候就必须考虑每个可以优化的细节了，一个一个细小的优化点累积起来，对于代码的运行效率绝对是有提升的。\n代码优化的目标是：\n1、减小代码的体积\n2、提高代码运行的效率\n代码优化细节 1、尽量指定类、方法的 final 修饰符 带有 final 修饰符的类是不可派生的。在 Java 核心 API 中，有许多应用 final 的例子，例如 java.lang.String，整个类都是 final 的。为类指定 final 修饰符可以让类不可以被继承，为方法指定 final 修饰符可以让方法不可以被重写。如果指定了一个类为 final，则该类所有的方法都是 final 的。Java 编译器会寻找机会内联所有的 final 方法，内联对于提升 Java 运行效率作用重大，具体参见 Java 运行期优化。此举能够使性能平均提高 50%。\n2、尽量重用对象 特别是 String 对象的使用，出现字符串连接时应该使用 StringBuilder/StringBuffer 代替。由于 Java 虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。\n3、尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。\n4、及时关闭流 Java 编程过程中，进行数据库连接、I/O 流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。\n5、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作：\nfor (int i = 0; i \u0026lt; list.size(); i++) {...}  建议替换为：\nfor (int i = 0, int length = list.size(); i \u0026lt; length; i++) {...}  这样，在 list.size() 很大的时候，就减少了很多的消耗\n6、尽量采用懒加载的策略，即在需要的时候才创建 例如：\nString str = \u0026quot;aaa\u0026quot;; if (i == 1){ list.add(str); }  建议替换为：\nif (i == 1){ String str = \u0026quot;aaa\u0026quot;; list.add(str); }  7、慎用异常 异常对性能不利。抛出异常首先要创建一个新的对象，Throwable 接口的构造函数调用名为 fillInStackTrace()的本地同步方法，fillInStackTrace() 方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java 虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。\n8、不要在循环中使用 try…catch…，应该把其放在最外层 除非不得已。如果毫无理由地这么写了，只要你的领导资深一点、有强迫症一点，八成就要骂你为什么写出这种垃圾代码来了\n9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如 ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet 等等，以 StringBuilder 为例：\n（1）StringBuilder() // 默认分配 16 个字符的空间\n（2）StringBuilder(int size) // 默认分配 size 个字符的空间\n（3）StringBuilder(String str) // 默认分配 16 个字符 +str.length() 个字符空间\n可以通过类（这里指的不仅仅是上面的 StringBuilder）的来设定它的初始化容量，这样可以明显地提升性能。比如 StringBuilder 吧，length 表示当前的 StringBuilder 能保持的字符数量。因为当 StringBuilder 达到最大容量的时候，它会将自身容量增加到当前的 2 倍再加 2，无论何时只要 StringBuilder 达到它的最大容量，它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中—- 这是十分耗费性能的一个操作。试想，如果能预估到字符数组中大概要存放 5000 个字符而不指定长度，最接近 5000 的 2 次幂是 4096，每次扩容加的 2 不管，那么：\n（1）在 4096 的基础上，再申请 8194 个大小的字符数组，加起来相当于一次申请了 12290 个大小的字符数组，如果一开始能指定 5000 个大小的字符数组，就节省了一倍以上的空间\n（2）把原来的 4096 个字符拷贝到新的的字符数组中去\n这样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的，这会带来立竿见影的效果。但是，注意，像 HashMap 这种是以数组 + 链表实现的集合，别把初始大小和你估计的大小设置得一样，因为一个 table 上只连接一个对象的可能性几乎为 0。初始大小建议设置为 2 的 N 次幂，如果能估计到有 2000 个元素，设置成 new HashMap(128)、new HashMap(256) 都可以。\n10、当复制大量数据时，使用 System.arraycopy() 命令 11、乘法和除法使用移位操作 例如：\nfor (val = 0; val \u0026lt; 100000; val += 5){ a = val * 8; b = val / 2; }  用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为：\nfor (val = 0; val \u0026lt; 100000; val += 5){ a = val \u0026lt;\u0026lt; 3; b = val \u0026gt;\u0026gt; 1; }  移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。\n12、循环内不要不断创建对象引用 例如：\nfor (int i = 1; i \u0026lt;= count; i++){ Object obj = new Object(); }  这种做法会导致内存中有 count 份 Object 对象引用存在，count 很大的话，就耗费内存了，建议为改为：\nObject obj = null; for (int i = 0; i \u0026lt;= count; i++) { obj = new Object(); }  这样的话，内存中只有一份 Object 对象引用，每次 new Object() 的时候，Object 对象引用指向不同的 Object 罢了，但是内存中只有一份，这样就大大节省了内存空间了。\n13、基于效率和类型检查的考虑，应该尽可能使用 array，无法确定数组大小时才使用 ArrayList 14、尽量使用 HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用 Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销\n15、不要将数组声明为 public static final 因为这毫无意义，这样只是定义了引用为 static final，数组的内容还是可以随意改变的，将数组声明为 public 更是一个安全漏洞，这意味着这个数组可以被外部类所改变\n16、尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面：\n（1）控制资源的使用，通过线程同步来控制资源的并发访问\n（2）控制实例的产生，以达到节约资源的目的\n（3）控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信\n17、尽量避免随意使用静态变量 要知道，当某个对象被定义为 static 的变量所引用，那么 gc 通常是不会回收这个对象所占有的堆内存的，如：\npublic class A{ private static B b = new B(); }\n此时静态变量 b 的生命周期与 A 类相同，如果 A 类不被卸载，那么引用 B 指向的 B 对象会常驻内存，直到程序终止\n18、及时清除不再需要的会话 为了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为 30 分钟。当应用服务器需要保存更多的会话时，如果内存不足，那么操作系统会把部分数据转移到磁盘，应用服务器也可能根据 MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁盘，那么必须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调用 HttpSession 的 invalidate() 方法清除会话。\n19、实现 RandomAccess 接口的集合比如 ArrayList，应当使用最普通的 for 循环而不是 foreach 循环来遍历 这是 JDK 推荐给用户的。JDK API 对于 RandomAccess 接口的解释是：实现 RandomAccess 接口用来表明其支持快速随机访问，此接口的主要目的是允许一般的算法更改其行为，从而将其应用到随机或连续访问列表时能提供良好的性能。实际经验表明，实现 RandomAccess 接口的类实例，假如是随机访问的，使用普通 for 循环效率将高于使用 foreach 循环；反过来，如果是顺序访问的，则使用 Iterator 会效率更高。可以使用类似如下的代码作判断：\nif (list instanceof RandomAccess){ for (int i = 0; i \u0026lt; list.size(); i++){...} }else{ Iterator iterator = list.iterable(); while (iterator.hasNext()){ iterator.next() } }  foreach 循环的底层实现原理就是迭代器 Iterator，参见 Java 语法糖 1：可变长度参数以及 foreach 循环原理。所以后半句”反过来，如果是顺序访问的，则使用 Iterator 会效率更高”的意思就是顺序访问的那些类实例，使用 foreach 循环去遍历。\n20、使用同步代码块替代同步方法 这点在多线程模块中的 synchronized 锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。\n21、将常量声明为 static final，并以大写命名 这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量\n22、不要创建一些不使用的对象，不要导入一些不使用的类 这毫无意义，如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”，那么请删除这些无用的内容\n23、程序运行过程中避免使用反射 关于，请参见反射。反射是 Java 提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运行过程中使用尤其是频繁使用反射机制，特别是 Method 的 invoke 方法，如果确实有必要，一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存—- 用户只关心和对端交互的时候获取最快的响应速度，并不关心对端的项目启动花多久时间。\n24、使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程\n25、使用带缓冲的输入输出流进行 IO 操作 带缓冲的输入输出流，即 BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升 IO 效率\n26、顺序插入和随机访问比较多的场景使用 ArrayList，元素删除和中间插入比较多的场景使用 LinkedList\n这个，理解 ArrayList 和 LinkedList 的原理就知道了\n27、不要让 public 方法中有太多的形参 public 方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处：\n1、违反了面向对象的编程思想，Java 讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合\n2、参数太多势必导致方法调用的出错概率增加\n至于这个”太多”指的是多少个，3、4 个吧。比如我们用 JDBC 写一个 insertStudentInfo 方法，有 10 个学生信息字段要插如 Student 表中，可以把这 10 个参数封装在一个实体类中，作为 insert 方法的形参\n28、字符串变量和字符串常量 equals 的时候将字符串常量写在前面 这是一个比较常见的小技巧了，如果有以下代码：\nString str = \u0026quot;123\u0026quot;; if (str.equals(\u0026quot;123\u0026quot;)) { ... }  建议修改为：\nString str = \u0026quot;123\u0026quot;; if (\u0026quot;123\u0026quot;.equals(str)){ ... }  这么做主要是可以避免空指针异常\n29、请知道，在 java 中 if (i == 1) 和 if (1 == i) 是没有区别的，但从阅读习惯上讲，建议使用前者 平时有人问，”if (i == 1)”和”if (1== i)”有没有区别，这就要从 C/C++ 讲起。\n在 C/C++ 中，”if (i == 1)”判断条件成立，是以 0 与非 0 为基准的，0 表示 false，非 0 表示 true，如果有这么一段代码：\nint i = 2; if (i == 1){ ... }else{ ... }  C/C++ 判断”i==1″不成立，所以以 0 表示，即 false。但是如果：\nint i = 2; if (i = 1) { ... }else{ ... }  万一程序员一个不小心，把”if (i == 1)”写成”if (i = 1)”，这样就有问题了。在 if 之内将 i 赋值为 1，if 判断里面的内容非 0，返回的就是 true 了，但是明明 i 为 2，比较的值是 1，应该返回的 false。这种情况在 C/C++ 的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在 if 语句中不正确的赋值操作，建议将 if 语句写为：\nint i = 2; if (1 == i) { ... }else{ ... }  这样，即使开发者不小心写成了”1 = i”，C/C++ 编译器也可以第一时间检查出来，因为我们可以对一个变量赋值 i 为 1，但是不能对一个常量赋值 1 为 i。\n但是，在 Java 中，C/C++ 这种”if (i = 1)”的语法是不可能出现的，因为一旦写了这种语法，Java 就会编译报错”Type mismatch: cannot convert from int to boolean”。但是，尽管 Java 的”if (i == 1)”和”if (1 == i)”在语义上没有任何区别，但是从阅读习惯上讲，建议使用前者会更好些。\n30、不要对数组使用 toString() 方法 看一下对数组使用 toString() 打印出来的是什么：\npublic static void main(String\\[\\] args){ int\\[\\] is = new int\\[\\]{1, 2, 3}; System.out.println(is.toString()); }  结果是：\n[I@18a992f  本意是想打印出数组内容，却有可能因为数组引用 is 为空而导致空指针异常。不过虽然对数组 toString()没有意义，但是对集合 toString() 是可以打印出集合里面的内容的，因为集合的父类 AbstractCollections 重写了 Object 的 toString() 方法。\n31、不要对超出范围的基本数据类型做向下强制转型 这绝不会得到想要的结果：\npublic static void main(String\\[\\] args){ long l = 12345678901234L; int i = (int)l; System.out.println(i); }  我们可能期望得到其中的某几位，但是结果却是：\n1942892530  解释一下。Java 中 long 是 8 个字节 64 位的，所以 12345678901234 在计算机中的表示应该是：\n0000 0000 0000 0000 0000 1011 0011 1010 0111 0011 1100 1110 0010 1111 1111 0010\n一个 int 型数据是 4 个字节 32 位的，从低位取出上面这串二进制数据的前 32 位是：\n0111 0011 1100 1110 0010 1111 1111 0010\n这串二进制表示为十进制 1942892530，所以就是我们上面的控制台上输出的内容。从这个例子上还能顺便得到两个结论：\n1、整型默认的数据类型是 int，long l = 12345678901234L，这个数字已经超出了 int 的范围了，所以最后有一个 L，表示这是一个 long 型数。顺便，浮点型的默认类型是 double，所以定义 float 的时候要写成”\u0026rdquo;float f = 3.5f”\n2、接下来再写一句”int ii = l + i;”会报错，因为 long + int 是一个 long，不能赋值给 int\n32、公用的集合类中不使用的数据一定要及时 remove 掉 如果一个集合类是公用的（也就是说不是方法里面的属性），那么这个集合里面的元素是不会自动释放的，因为始终有引用指向它们。所以，如果公用集合里面的某些数据不使用而不去 remove 掉它们，那么将会造成这个公用集合不断增大，使得系统有内存泄露的隐患。\n33、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf( 数据) 次之、数据 +”\u0026rdquo; 最慢\n把一个基本数据类型转为一般有三种方式，我有一个 Integer 型数据 i，可以使用 i.toString()、String.valueOf(i)、i+”\u0026rdquo; 三种方式，三种方式的效率如何，看一个测试：\npublic static void main(String\\[\\] args){ int loopTime = 50000; Integer i = 0; long startTime = System.currentTimeMillis(); for (int j = 0; j \u0026lt; loopTime; j++){ String str = String.valueOf(i); } System.out.println(\u0026quot;String.valueOf()：\u0026quot; + (System.currentTimeMillis() \\- startTime) + \u0026quot;ms\u0026quot;); startTime = System.currentTimeMillis(); for (int j = 0; j \u0026lt; loopTime; j++){ String str = i.toString(); } System.out.println(\u0026quot;Integer.toString()：\u0026quot; + (System.currentTimeMillis() \\- startTime) + \u0026quot;ms\u0026quot;); startTime = System.currentTimeMillis(); for (int j = 0; j \u0026lt; loopTime; j++){ String str = i + \u0026quot;\u0026quot;; } System.out.println(\u0026quot;i + \\\\\u0026quot;\\\\\u0026quot;：\u0026quot; + (System.currentTimeMillis() \\- startTime) + \u0026quot;ms\u0026quot;); }  运行结果为：\nString.valueOf()：11ms Integer.toString()：5ms i + \u0026quot;\u0026quot;：25ms  所以以后遇到把一个基本数据类型转为 String 的时候，优先考虑使用 toString() 方法。至于为什么，很简单：\n1、String.valueOf()方法底层调用了 Integer.toString() 方法，但是会在调用前做空判断\n2、Integer.toString() 方法就不说了，直接调用了\n3、i + “”底层使用了 StringBuilder 实现，先用 append 方法拼接，再用 toString() 方法获取字符串\n三者对比下来，明显是 2 最快、1 次之、3 最慢\n34、使用最有效率的方式去遍历 Map 遍历 Map 的方式有很多，通常场景下我们需要的是遍历 Map 中的 Key 和 Value，那么推荐使用的、效率最高的方式是：\npublic static void main(String\\[\\] args){ HashMap hm = new HashMap(); hm.put(\u0026quot;111\u0026quot;, \u0026quot;222\u0026quot;); Set\\\u0026gt; entrySet = hm.entrySet(); Iterator\\\u0026gt; iter = entrySet.iterator(); while (iter.hasNext()){ Map.Entry entry = iter.next(); System.out.println(entry.getKey() \\+ \u0026quot;\\\\t\u0026quot; + entry.getValue()); } }  如果你只是想遍历一下这个 Map 的 key 值，那用”Set keySet = hm.keySet();”会比较合适一些\n35、对资源的 close() 建议分开操作 意思是，比如我有这么一段代码：\ntry{ XXX.close(); YYY.close(); }catch (Exception e){ ... }  建议修改为：\ntry{ XXX.close(); }catch (Exception e) { ... } try{ YYY.close(); }catch (Exception e) { ... }  虽然有些麻烦，却能避免资源泄露。我们想，如果没有修改过的代码，万一 XXX.close()抛异常了，那么就进入了 cath 块中了，YYY.close() 不会执行，YYY 这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为下面的写法之后，就保证了无论如何 XXX 和 YYY 都会被 close 掉。\n","id":0,"section":"posts","summary":"35 个 Java 代码优化小技巧 前言 代码优化，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运行效率有什么影响呢","tags":["优化"],"title":"35 个 Java 代码优化小技巧","uri":"https://lcoco.github.io/2019/11/35-%E4%B8%AA-java-%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E5%B0%8F%E6%8A%80%E5%B7%A7/","year":"2019"},{"content":"","id":1,"section":"posts","summary":"","tags":["index"],"title":"Posts","uri":"https://lcoco.github.io/posts/","year":"2019"},{"content":" Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如何使用python通过函数式编程完成excel中的数据处理及分析工作。在Python中pandas库用于数据处理 ，我们从1787页的pandas官网文档中总结出最常用的36个函数，通过这些函数介绍如何通过python完成数据生成和导入，数据清洗，预处理，以及最常见的数据分类，数据筛选，分类 汇总，透视等最常见的操作。 文章内容共分为9个部分。这是第一篇，介绍前3部分内容，数据表生成，数据表查看，和数据清洗。以下是《像Excel一样使用python进行数据分析》系列文章的目录。\n\n1， 生成数据表 第一部分是生成数据表，常见的生成方法有两种，第一种是导入外部数据，第二种是直接写入数据。 Excel中的文件菜单中提供了获取外部数据的功能，支持数据库和文本文件和页面的多种数据源导入。\n\npython支持从多种类型的数据导入。在开始使用python进行数据导入前需要先导入pandas库，为了方便起见，我们也同时导入numpy库。\nimport numpy as np import pandas as pd  导入数据表 下面分别是从excel和csv格式文件导入数据并创建数据表的方法。代码是最简模式，里面有很多可选参数设置，例如列名称，索引列，数据格式等等。感兴趣的朋友可以参考pandas的\n官方文档。\ndf=pd.DataFrame(pd.read_csv('name.csv',header=1)) df=pd.DataFrame(pd.read_excel('name.xlsx'))  创建数据表 另一种方法是通过直接写入数据来生成数据表，excel中直接在单元格中输入数据就可以，python中通过下面的代码来实现。生成数据表的函数是pandas库中的DateFrame函数，数据表一共有6行数据，每行有6个字段。在数据中我们特意设置了一些NA值和有问题的字段，例如包含空格等。后面将在数据清洗步骤进行处理。后面我们将统一以DataFrame的简称df来命名数据表。\ndf = pd.DataFrame({\u0026amp;quot;id\u0026amp;quot;:[1001,1002,1003,1004,1005,1006], \u0026amp;quot;date\u0026amp;quot;:pd.date_range('20130102', periods=6), \u0026amp;quot;city\u0026amp;quot;:['Beijing ', 'SH', ' guangzhou ', 'Shenzhen', 'shanghai', 'BEIJING '], \u0026amp;quot;age\u0026amp;quot;:[23,44,54,32,34,32], \u0026amp;quot;category\u0026amp;quot;:['100-A','100-B','110-A','110-C','210-A','130-F'], \u0026amp;quot;price\u0026amp;quot;:[1200,np.nan,2133,5433,np.nan,4432]}, columns =['id','date','city','category','age','price'])  这是刚刚创建的数据表，我们没有设置索引列，price字段中包含有NA值，city字段中还包含了一些脏数据。\n 2，数据表检查\n第二部分是对数据表进行检查，python中处理的数据量通常会比较大，比如我们之前的文章中介绍的纽约出租车数据和Citibike的骑行数据，数据量都在千万级，我们无法一目了然的 了解数据表的整体情况，必须要通过一些方法来获得数据表的关键信息。数据表检查的另一个目的是了解数据的概况，例如整个数据表的大小，所占空间，数据格式，是否有空值和重复项和具体的数据内容。为后面的清洗和预处理做好准备。\n数据维度(行列) Excel中可以通过CTRL+向下的光标键，和CTRL+向右的光标键来查看行号和列号。Python中使用shape函数来查看数据表的维度，也就是行数和列数，函数返回的结果(6,6)表示数据表有6行，6列。下面是具体的代码。\n#查看数据表的维度 df.shape (6, 6)  数据表信息 使用info函数查看数据表的整体信息，这里返回的信息比较多，包括数据维度，列名称，数据格式和所占空间等信息。\n#数据表信息 df.info() \u0026amp;amp;lt;class 'pandas.core.frame.DataFrame'\u0026amp;amp;gt; RangeIndex: 6 entries, 0 to 5 Data columns (total 6 columns): id 6 non-null int64 date 6 non-null datetime64[ns] city 6 non-null object category 6 non-null object age 6 non-null int64 price 4 non-null float64 dtypes: datetime64[ns](1), float64(1), int64(2), object(2) memory usage: 368.0+ bytes  查看数据格式 Excel中通过选中单元格并查看开始菜单中的数值类型来判断数据的格式。Python中使用dtypes函数来返回数据格式。\n\nDtypes是一个查看数据格式的函数，可以一次性查看数据表中所有数据的格式，也可以指定一列来单独查看。\n#查看数据表各列格式 df.dtypes id int64 date datetime64[ns] city object category object age int64 price float64 dtype: object  #查看单列格式 df['B'].dtype dtype('int64')  查看空值 Excel中查看空值的方法是使用“定位条件”功能对数据表中的空值进行定位。“定位条件”在“开始”目录下的“查找和选择”目录中。\n\nIsnull是Python中检验空值的函数，返回的结果是逻辑值，包含空值返回True，不包含则返回False。可以对整个数据表进行检查，也可以单独对某一列进行空值检查。\n#检查数据空值 df.isnull()  [\n](http://bluewhale.cc/wp-content/uploads/2017/04/df_dropna.png)\n#检查特定列空值 df['price'].isnull() 0 False 1 True 2 False 3 False 4 True 5 False Name: price, dtype: bool  查看唯一值 Excel中查看唯一值的方法是使用“条件格式”对唯一值进行颜色标记。Python中使用unique函数查看唯一值。\n\nUnique是查看唯一值的函数，只能对数据表中的特定列进行检查。下面是代码，返回的结果是该列中的唯一值。类似与Excel中删除重复项后的结果。\n#查看city列中的唯一值 df['city'].unique() array(['Beijing ', 'SH', ' guangzhou ', 'Shenzhen', 'shanghai', 'BEIJING '], dtype=object)  查看数据表数值 Python中的Values函数用来查看数据表中的数值。以数组的形式返回，不包含表头信息。\n#查看数据表的值 df.values array([[1001, Timestamp('2013-01-02 00:00:00'), 'Beijing ', '100-A', 23, 1200.0], [1002, Timestamp('2013-01-03 00:00:00'), 'SH', '100-B', 44, nan], [1003, Timestamp('2013-01-04 00:00:00'), ' guangzhou ', '110-A', 54, 2133.0], [1004, Timestamp('2013-01-05 00:00:00'), 'Shenzhen', '110-C', 32, 5433.0], [1005, Timestamp('2013-01-06 00:00:00'), 'shanghai', '210-A', 34, nan], [1006, Timestamp('2013-01-07 00:00:00'), 'BEIJING ', '130-F', 32, 4432.0]], dtype=object)  查看列名称 Colums函数用来单独查看数据表中的列名称。\n#查看列名称 df.columns Index(['id', 'date', 'city', 'category', 'age', 'price'], dtype='object')  查看前10行数据 Head函数用来查看数据表中的前N行数据，默认head()显示前10行数据，可以自己设置参数值来确定查看的行数。下面的代码中设置查看前3行的数据。\n#查看前3行数据 df.head(3)  \n查看后10行数据 Tail行数与head函数相反，用来查看数据表中后N行的数据，默认tail()显示后10行数据，可以自己设置参数值来确定查看的行数。下面的代码中设置查看后3行的数据。\n#查看最后3行 df.tail(3)  \n3，数据表清洗 第三部分是对数据表中的问题进行清洗。主要内容包括对空值，大小写问题，数据格式和重复值的处理。这里不包含对数据间的逻辑验证。\n处理空值(删除或填充) 我们在创建数据表的时候在price字段中故意设置了几个NA值。对于空值的处理方式有很多种，可以直接删除包含空值的数据，也可以对空值进行填充，比如用0填充或者用均值填充。还可以根据不同字段的逻辑对空值进行推算。\nExcel中可以通过“查找和替换”功能对空值进行处理，将空值统一替换为0或均值。也可以通过“定位”空值来实现。\n\nPython中处理空值的方法比较灵活，可以使用 Dropna函数用来删除数据表中包含空值的数据，也可以使用fillna函数对空值进行填充。下面的代码和结果中可以看到使用dropna函数后，包含NA值的两个字段已经不见了。返回的是一个不包含空值的数据表。\n#删除数据表中含有空值的行 df.dropna(how='any')  \n除此之外也可以使用数字对空值进行填充，下面的代码使用fillna函数对空值字段填充数字0。\n#使用数字0填充数据表中空值 df.fillna(value=0)  我们选择填充的方式来处理空值，使用price列的均值来填充NA字段，同样使用fillna函数，在要填充的数值中使用mean函数先计算price列当前的均值，然后使用这个均值对NA进行填\n充。可以看到两个空值字段显示为3299.5\n#使用price均值对NA进行填充 df['price'].fillna(df['price'].mean()) 0 1200.0 1 3299.5 2 2133.0 3 5433.0 4 3299.5 5 4432.0 Name: price, dtype: float64  \n清理空格 除了空值，字符中的空格也是数据清洗中一个常见的问题，下面是清除字符中空格的代码。\n#清除city字段中的字符空格 df['city']=df['city'].map(str.strip)  大小写转换 在英文字段中，字母的大小写不统一也是一个常见的问题。Excel中有UPPER，LOWER等函数，python中也有同名函数用来解决大小写的问题。在数据表的city列中就存在这样的问题。我们将city列的所有字母转换为小写。下面是具体的代码和结果。\n#city列大小写转换 df['city']=df['city'].str.lower()   更改数据格式 Excel中通过“设置单元格格式”功能可以修改数据格式。Python中通过astype函数用来修改数据格式。\n\nPython中dtype是查看数据格式的函数，与之对应的是astype函数，用来更改数据格式。下面的代码中将price字段的值修改为int格式。\n#更改数据格式 df['price'].astype('int') 0 1200 1 3299 2 2133 3 5433 4 3299 5 4432 Name: price, dtype: int32  更改列名称 Rename是更改列名称的函数，我们将来数据表中的category列更改为category-size。下面是具体的代码和更改后的结果。\n#更改列名称 df.rename(columns={'category': 'category-size'})  \n删除重复值 很多数据表中还包含重复值的问题，Excel的数据目录下有“删除重复项”的功能，可以用来删除数据表中的重复值。默认Excel会保留最先出现的数据，删除后面重复出现的数据。\n\nPython中使用drop_duplicates函数删除重复值。我们以数据表中的city列为例，city字段中存在重复值。默认情况下drop_duplicates()将删除后出现的重复值(与excel逻辑一致)。增加keep=’last’参数后将删除最先出现的重复值，保留最后的值。下面是具体的代码和比较结果。\n原始的city列中beijing存在重复，分别在第一位和最后一位。\ndf['city'] 0 beijing 1 sh 2 guangzhou 3 shenzhen 4 shanghai 5 beijing Name: city, dtype: object  使用默认的drop_duplicates()函数删除重复值，从结果中可以看到第一位的beijing被保留，最后出现的beijing被删除。\n#删除后出现的重复值 df['city'].drop_duplicates() 0 beijing 1 sh 2 guangzhou 3 shenzhen 4 shanghai Name: city, dtype: object  设置keep=\u0026#8217;last‘’参数后，与之前删除重复值的结果相反，第一位出现的beijing被删除，保留了最后一位出现的beijing。\n#删除先出现的重复值 df['city'].drop_duplicates(keep='last') 1 sh 2 guangzhou 3 shenzhen 4 shanghai 5 beijing Name: city, dtype: objec  数值修改及替换 数据清洗中最后一个问题是数值修改或替换，Excel中使用“查找和替换”功能就可以实现数值的替换。\n\nPython中使用replace函数实现数据替换。数据表中city字段上海存在两种写法，分别为shanghai和SH。我们使用replace函数对SH进行替换。\n#数据替换 df['city'].replace('sh', 'shanghai') 0 beijing 1 shanghai 2 guangzhou 3 shenzhen 4 shanghai 5 beijing Name: city, dtype: object  在第二篇文章中我们将继续介绍4-6部分的内容，分别为数据预处理，数据提取和数据筛选三部分的问题。感兴趣的朋友请继续关注。\n######文章及图片版权归 蓝鲸（王彦平）所有。转自“蓝鲸网站分析博客”。\n","id":2,"section":"posts","summary":"Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如何使用python通过函数式编程完成excel中的数","tags":["转载"],"title":"像Excel一样使用python进行数据分析-(1)","uri":"https://lcoco.github.io/2019/11/%E5%83%8Fexcel%E4%B8%80%E6%A0%B7%E4%BD%BF%E7%94%A8python/","year":"2019"},{"content":" 像Excel一样使用python进行数据分析-(2) Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如何使用python通过函数式编程完成excel中的数据处理及分析工作。在Python中pandas库用于数据处理，我们从1787页的pandas官网文档中总结出最常用的36个函数，通过这些函数介绍如何通过python完成数据生成和导入，数据清洗，预处理，以及最常见的数据分类，数据筛选，分类汇总，透视等最常见的操作。\n这个系列文章内容共分为9个部分。已由人民邮电出版社出版，感兴趣的朋友可以在异步社区获取完整版。\n\n第一篇文章链接在这里：像Excel一样使用python进行数据分析-(1)\n本篇文章这是系列的第二篇，介绍第4-6部分的内容，数据表生成，数据表查看，和数据清洗。\n 4，数据预处理\n第四部分是数据的预处理，对清洗完的数据进行整理以便后期的统计和分析工作。主要包括数据表的合并，排序，数值分列，数据分\n组及标记等工作。\n数据表合并 首先是对不同的数据表进行合并，我们这里创建一个新的数据表df1，并将df和df1两个数据表进行合并。在Excel中没有直接完成数据表合并的功能，可以通过VLOOKUP函数分步实现。在python中可以通过merge函数一次性实现。下面建立df1数据表，用于和df数据表进行合并。\n#创建df1数据表 df1=pd.DataFrame({\u0026amp;quot;id\u0026amp;quot;:[1001,1002,1003,1004,1005,1006,1007,1008], \u0026amp;quot;gender\u0026amp;quot;:['male','female','male','female','male','female','male','female'], \u0026amp;quot;pay\u0026amp;quot;:['Y','N','Y','Y','N','Y','N','Y',], \u0026amp;quot;m-point\u0026amp;quot;:[10,12,20,40,40,40,30,20]})  \n使用merge函数对两个数据表进行合并，合并的方式为inner，将两个数据表中共有的数据匹配到一起生成新的数据表。并命名为df_inner。\n#数据表匹配合并，inner模式 df_inner=pd.merge(df,df1,how='inner')  \n除了inner方式以外，合并的方式还有left，right和outer方式。这几种方式的差别在我其他的文章中有详细的说明和对比。\n#其他数据表匹配模式 df_left=pd.merge(df,df1,how='left') df_right=pd.merge(df,df1,how='right') df_outer=pd.merge(df,df1,how='outer')  设置索引列 完成数据表的合并后，我们对df_inner数据表设置索引列，索引列的功能很多，可以进行数据提取，汇总，也可以进行数据筛选等。\n设置索引的函数为set_index。\n#设置索引列 df_inner.set_index('id')   排序(按索引，按数值)\nExcel中可以通过数据目录下的排序按钮直接对数据表进行排序，比较简单。Python中需要使用ort_values函数和sort_index函数完成排序。\n\n在python中，既可以按索引对数据表进行排序，也可以看制定列的数值进行排序。首先我们按age列中用户的年龄对数据表进行排序。\n使用的函数为sort_values。\n#按特定列的值排序 df_inner.sort_values(by=['age'])  \nSort_index函数用来将数据表按索引列的值进行排序。\n#按索引列排序 df_inner.sort_index()   数据分组\nExcel中可以通过VLOOKUP函数进行近似匹配来完成对数值的分组，或者使用“数据透视表”来完成分组。相应的 python中使用where函数完成数据分组。\nWhere函数用来对数据进行判断和分组，下面的代码中我们对price列的值进行判断，将符合条件的分为一组，不符合条件的分为另一组，并使用group字段进行标记。\n#如果price列的值\u0026amp;gt;3000，group列显示high，否则显示low df_inner['group'] = np.where(df_inner['price'] \u0026amp;gt; 3000,'high','low')  \n除了where函数以外，还可以对多个字段的值进行判断后对数据进行分组，下面的代码中对city列等于beijing并且price列大于等于4000的数据标记为1。\n#对复合多个条件的数据进行分组标记 df_inner.loc[(df_inner['city'] == 'beijing') \u0026amp;amp; (df_inner['price'] \u0026amp;gt;= 4000), 'sign']=1   数据分列\n与数据分组相反的是对数值进行分列，Excel中的数据目录下提供“分列”功能。在python中使用split函数实现分列。\n\n在数据表中category列中的数据包含有两个信息，前面的数字为类别id，后面的字母为size值。中间以连字符进行连接。我们使用split函数对这个字段进行拆分，并将拆分后的数据表匹配回原数据表中。\n#对category字段的值依次进行分列，并创建数据表，索引值为df_inner的索引列，列名称为category和size pd.DataFrame((x.split('-') for x in df_inner['category']),index=df_inner.index,columns=['category','size'])  \n#将完成分列后的数据表与原df_inner数据表进行匹配 df_inner=pd.merge(df_inner,split,right_index=True, left_index=True)   5,数据提取\n第五部分是数据提取，也是数据分析中最常见的一个工作。这部分主要使用三个函数，loc，iloc和ix，loc函数按标签值进行提取，iloc按位置进行提取，ix可以同时按标签和位置进行提取。下面介绍每一种函数的使用方法。\n按标签提取(loc) Loc函数按数据表的索引标签进行提取，下面的代码中提取了索引列为3的单条数据。\n#按索引提取单行的数值 df_inner.loc[3] id 1004 date 2013-01-05 00:00:00 city shenzhen category 110-C age 32 price 5433 gender female m-point 40 pay Y group high sign NaN category_1 110 size C Name: 3, dtype: object  使用冒号可以限定提取数据的范围，冒号前面为开始的标签值，后面为结束的标签值。下面提取了0到5的数据行。\n#按索引提取区域行数值 df_inner.loc[0:5]  \nReset_index函数用于恢复索引，这里我们重新将date字段的日期设置为数据表的索引，并按日期进行数据提取。\n#重设索引 df_inner.reset_index()  \n#设置日期为索引 df_inner=df_inner.set_index('date')  \n使用冒号限定提取数据的范围，冒号前面为空表示从0开始。提取所有2013年1月4日以前的数据。\n#提取4日之前的所有数据 df_inner[:'2013-01-04']  \n按位置提取(iloc) 使用iloc函数按位置对数据表中的数据进行提取，这里冒号前后的数字不再是索引的标签名称，而是数据所在的位置，从0开始。\n#使用iloc按位置区域提取数据 df_inner.iloc[:3,:2]  \niloc函数除了可以按区域提取数据，还可以按位置逐条提取，前面方括号中的0,2,5表示数据所在行的位置，后面方括号中的数表示所在列的位置。\n#使用iloc按位置单独提取数据 df_inner.iloc[[0,2,5],[4,5]]  \n按标签和位置提取（ix） ix是loc和iloc的混合，既能按索引标签提取，也能按位置进行数据提取。下面代码中行的位置按索引日期设置，列按位置设置。\n#使用ix按索引标签和位置混合提取数据 df_inner.ix[:'2013-01-03',:4]   按条件提取（区域和条件值）\n除了按标签和位置提起数据以外，还可以按具体的条件进行数据。下面使用loc和isin两个函数配合使用，按指定条件对数据进行提取 。\n使用isin函数对city中的值是否为beijing进行判断。\n#判断city列的值是否为beijing df_inner['city'].isin(['beijing']) date 2013-01-02 True 2013-01-05 False 2013-01-07 True 2013-01-06 False 2013-01-03 False 2013-01-04 False Name: city, dtype: bool  \u0026nbsp;\n将isin函数嵌套到loc的数据提取函数中，将判断结果为Ture数据提取出来。这里我们把判断条件改为city值是否为beijing和 shanghai。如果是就把这条数据提取出来。\n#先判断city列里是否包含beijing和shanghai，然后将复合条件的数据提取出来。 df_inner.loc[df_inner['city'].isin(['beijing','shanghai'])]  \n数值提取还可以完成类似数据分列的工作，从合并的数值中提取出制定的数值。\ncategory=df_inner['category'] 0 100-A 3 110-C 5 130-F 4 210-A 1 100-B 2 110-A Name: category, dtype: object  #提取前三个字符，并生成数据表 pd.DataFrame(category.str[:3])   6，数据筛选\n第六部分为数据筛选，使用与，或，非三个条件配合大于，小于和等于对数据进行筛选，并进行计数和求和。与excel中的筛选功能和countifs和sumifs功能相似。\n按条件筛选（与，或，非） Excel数据目录下提供了“筛选”功能，用于对数据表按不同的条件进行筛选。Python中使用loc函数配合筛选条件来完成筛选功能。配合sum和count函数还能实现excel中sumif和countif函数的功能。\n\n使用“与”条件进行筛选，条件是年龄大于25岁，并且城市为beijing。筛选后只有一条数据符合要求。\n#使用“与”条件进行筛选 df_inner.loc[(df_inner['age'] \u0026amp;gt; 25) \u0026amp;amp; (df_inner['city'] == 'beijing'), ['id','city','age','category','gender']]  \n使用“或”条件进行筛选，年龄大于25岁或城市为beijing。筛选后有6条数据符合要求。\n#使用“或”条件筛选 df_inner.loc[(df_inner['age'] \u0026amp;gt; 25) | (df_inner['city'] == 'beijing'), ['id','city','age','category','gender']].sort (['age'])  \n在前面的代码后增加price字段以及sum函数，按筛选后的结果将price字段值进行求和，相当于excel中sumifs的功能。\n#对筛选后的数据按price字段进行求和 df_inner.loc[(df_inner['age'] \u0026amp;gt; 25) | (df_inner['city'] == 'beijing'), ['id','city','age','category','gender','price']].sort(['age']).price.sum() 19796  使用“非”条件进行筛选，城市不等于beijing。符合条件的数据有4条。将筛选结果按id列进行排序。\n#使用“非”条件进行筛选 df_inner.loc[(df_inner['city'] != 'beijing'), ['id','city','age','category','gender']].sort(['id'])  \n在前面的代码后面增加city列，并使用count函数进行计数。相当于excel中的countifs函数的功能。\n#对筛选后的数据按city列进行计数 df_inner.loc[(df_inner['city'] != 'beijing'), ['id','city','age','category','gender']].sort(['id']).city.count() 4  还有一种筛选的方式是用query函数。下面是具体的代码和筛选结果。\n#使用query函数进行筛选 df_inner.query('city == [\u0026amp;quot;beijing\u0026amp;quot;, \u0026amp;quot;shanghai\u0026amp;quot;]')  \n在前面的代码后增加price字段和sum函数。对筛选后的price字段进行求和，相当于excel中的sumifs函数的功能。\n#对筛选后的结果按price进行求和 df_inner.query('city == [\u0026amp;quot;beijing\u0026amp;quot;, \u0026amp;quot;shanghai\u0026amp;quot;]').price.sum() 12230  下一篇文章，也就是本系列的最后一篇我们将介绍7-9最后三部分的内容，分别为数据汇总，数据统计和数据输出。请朋友们继续关注 。\n【所有文章及图片版权归 蓝鲸（王彦平）所有。欢迎转载，但请注明转自“蓝鲸网站分析博客”。】\n","id":3,"section":"posts","summary":"像Excel一样使用python进行数据分析-(2) Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如","tags":["转载"],"title":"像Excel一样使用python进行数据分析-(2)","uri":"https://lcoco.github.io/2019/11/%E5%83%8Fexcel%E4%B8%80%E6%A0%B7%E4%BD%BF%E7%94%A8python2/","year":"2019"},{"content":" 像Excel一样使用python进行数据分析-(3) Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如何使用python通过函数式编程完成excel中的数据处理及分析工作。在Python中pandas库用于数据处理，我们从1787页的pandas官网文档中总结出最常用的36个函数，通过这些函数介绍如何通过python完成数据生成和导入，数据清洗，预处理，以及最常见的数据分类，数据筛选，分类汇总，透视等最常见的操作。\n这个系列文章内容共分为9个部分。已由人民邮电出版社出版，感兴趣的朋友可以在异步社区获取完整版。\n\n前两篇文章链接在这里：\n像Excel一样使用python进行数据分析-(1)\n像Excel一样使用python进行数据分析-(2)\n这是第三篇，介绍第7-9部分的内容，数据汇总，数据统计，和数据输出。\n\n7，数据汇总 第七部分是对数据进行分类汇总，Excel中使用分类汇总和数据透视可以按特定维度对数据进行汇总，python中使用的主要函数是groupby和pivot_table。下面分别介绍这两个函数的使用方法。\n分类汇总 Excel的数据目录下提供了“分类汇总”功能，可以按指定的字段和汇总方式对数据表进行汇总。Python中通过Groupby函数完成相应的操作，并可以支持多级分类汇总。\n\nGroupby是进行分类汇总的函数，使用方法很简单，制定要分组的列名称就可以，也可以同时制定多个列名称，groupby按列名称出现的顺序进行分组。同时要制定分组后的汇总方式，常见的是计数和求和两种。\n#对所有列进行计数汇总 df_inner.groupby('city').count()  \n可以在groupby中设置列名称来对特定的列进行汇总。下面的代码中按城市对id字段进行汇总计数。\n#对特定的ID列进行计数汇总 df_inner.groupby('city')['id'].count() city beijing 2 guangzhou 1 shanghai 2 shenzhen 1 Name: id, dtype: int64  在前面的基础上增加第二个列名称，分布对city和size两个字段进行计数汇总。\n#对两个字段进行汇总计数 df_inner.groupby(['city','size'])['id'].count() city size beijing A 1 F 1 guangzhou A 1 shanghai A 1 B 1 shenzhen C 1 Name: id, dtype: int64  除了计数和求和外，还可以对汇总后的数据同时按多个维度进行计算，下面的代码中按城市对price字段进行汇总，并分别计算price的数量，总金额和平均金额。\n#对city字段进行汇总并计算price的合计和均值。 df_inner.groupby('city')['price'].agg([len,np.sum, np.mean])   数据透视\nExcel中的插入目录下提供“数据透视表”功能对数据表按特定维度进行汇总。Python中也提供了数据透视表功能。通过pivot_table函数实现同样的效果。\n\n数据透视表也是常用的一种数据分类汇总方式，并且功能上比groupby要强大一些。下面的代码中设定city为行字段，size为列字段，price为值字段。分别计算price的数量和金额并且按行与列进行汇总。\n#数据透视表 pd.pivot_table(df_inner,index=[\u0026amp;quot;city\u0026amp;quot;],values=[\u0026amp;quot;price\u0026amp;quot;],columns=[\u0026amp;quot;size\u0026amp;quot;],aggfunc=[len,np.sum],fill_value=0,margins=True)  \n8，数据统计 第九部分为数据统计，这里主要介绍数据采样，标准差，协方差和相关系数的使用方法。\n数据采样 Excel的数据分析功能中提供了数据抽样的功能，如下图所示。Python通过sample函数完成数据采样。\n\nSample是进行数据采样的函数，设置n的数量就可以了。函数自动返回参与的结果。\n#简单的数据采样 df_inner.sample(n=3)  \nWeights参数是采样的权重，通过设置不同的权重可以更改采样的结果，权重高的数据将更有希望被选中。这里手动设置6条数据的权重值。将前面4个设置为0，后面两个分别设置为0.5。\n#手动设置采样权重 weights = [0, 0, 0, 0, 0.5, 0.5] df_inner.sample(n=2, weights=weights)  \n从采样结果中可以看出，后两条权重高的数据被选中。\n\nSample函数中还有一个参数replace，用来设置采样后是否放回。\n#采样后不放回 df_inner.sample(n=6, replace=False)  \n#采样后放回 df_inner.sample(n=6, replace=True)   描述统计\nExcel中的数据分析中提供了描述统计的功能。Python中可以通过Describe对数据进行描述统计。\n\nDescribe函数是进行描述统计的函数，自动生成数据的数量，均值，标准差等数据。下面的代码中对数据表进行描述统计，并使用round函数设置结果显示的小数位。并对结果数据进行转置。\n#数据表描述性统计 df_inner.describe().round(2).T  \n标准差\nPython中的Std函数用来接算特定数据列的标准差。\n#标准差 df_inner['price'].std() 1523.3516556155596  协方差\nExcel中的数据分析功能中提供协方差的计算，python中通过cov函数计算两个字段或数据表中各字段间的协方差。\n\nCov函数用来计算两个字段间的协方差，可以只对特定字段进行计算，也可以对整个数据表中各个列之间进行计算。\n#两个字段间的协方差 df_inner['price'].cov(df_inner['m-point']) 17263.200000000001  #数据表中所有字段间的协方差 df_inner.cov()  \n相关分析\nExcel的数据分析功能中提供了相关系数的计算功能，python中则通过corr函数完成相关分析的操作，并返回相关系数。\n\nCorr函数用来计算数据间的相关系数，可以单独对特定数据进行计算，也可以对整个数据表中各个列进行计算。相关系数在-1到1之间，接近1为正相关，接近-1为负相关，0为不相关。\n#相关性分析 df_inner['price'].corr(df_inner['m-point']) 0.77466555617085264  #数据表相关性分析 df_inner.corr()  \n9，数据输出 第九部分是数据输出，处理和分析完的数据可以输出为xlsx格式和csv格式。\n写入excel\n#输出到excel格式 df_inner.to_excel('excel_to_python.xlsx', sheet_name='bluewhale_cc')  \n写入csv\n#输出到CSV格式 df_inner.to_csv('excel_to_python.csv')  在数据处理的过程中，大部分基础工作是重复和机械的，对于这部分基础工作，我们可以使用自定义函数进行自动化。以下简单介绍对数据表信息获取自动化处理。\n#创建数据表 df = pd.DataFrame({\u0026amp;quot;id\u0026amp;quot;:[1001,1002,1003,1004,1005,1006], \u0026amp;quot;date\u0026amp;quot;:pd.date_range('20130102', periods=6), \u0026amp;quot;city\u0026amp;quot;:['Beijing ', 'SH', ' guangzhou ', 'Shenzhen', 'shanghai', 'BEIJING '], \u0026amp;quot;age\u0026amp;quot;:[23,44,54,32,34,32], \u0026amp;quot;category\u0026amp;quot;:['100-A','100-B','110-A','110-C','210-A','130-F'], \u0026amp;quot;price\u0026amp;quot;:[1200,np.nan,2133,5433,np.nan,4432]}, columns =['id','date','city','category','age','price'])  #创建自定义函数 def table_info(x): shape=x.shape types=x.dtypes colums=x.columns print(\u0026amp;quot;数据维度(行，列):\\n\u0026amp;quot;,shape) print(\u0026amp;quot;数据格式:\\n\u0026amp;quot;,types) print(\u0026amp;quot;列名称:\\n\u0026amp;quot;,colums)  #调用自定义函数获取df数据表信息并输出结果 table_info(df) 数据维度(行，列): (6, 6) 数据格式: id int64 date datetime64[ns] city object category object age int64 price float64 dtype: object 列名称: Index(['id', 'date', 'city', 'category', 'age', 'price'], dtype='object')  本篇是《像Excel一样使用python进行数据分析》系列文章的最后一篇。在这个系列中我们列举了python中36个简单的函数来实现excel中最常见的一些功能。感兴趣的朋友可以下载并阅读pandas官方文档，里面有更详细的函数说明。也欢迎给我留言进行交流。\n【所有文章及图片版权归 蓝鲸（王彦平）所有。欢迎转载，但请注明转自“蓝鲸网站分析博客”。】\n","id":4,"section":"posts","summary":"像Excel一样使用python进行数据分析-(3) Excel是数据分析中最常用的工具，本篇文章通过python与excel的功能对比介绍如","tags":["转载"],"title":"像Excel一样使用python进行数据分析-(3)","uri":"https://lcoco.github.io/2019/11/%E5%83%8Fexcel%E4%B8%80%E6%A0%B7%E4%BD%BF%E7%94%A8python3/","year":"2019"}],"tags":[{"title":"优化","uri":"https://lcoco.github.io/tags/%E4%BC%98%E5%8C%96/"},{"title":"转载","uri":"https://lcoco.github.io/tags/%E8%BD%AC%E8%BD%BD/"}]}